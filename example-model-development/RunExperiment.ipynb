{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c0b4a67890b9018593b09ad47235403e06a4a778d0fcca31c7c373ba0d2afff3",
   "display_name": "Python 3.8.5 64-bit ('ml-pipes-VBbH4xSK-py3.8': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4e3b28acd7a0957c37c0956cd76d2c0402b105ada09a22b696d0c202f94577cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ml-Pipes\n",
    "\n",
    "The objective of this project is to present a gentle introduction of how a machine learning model can be trained and deployed. And how [MLFlow](https://www.mlflow.org/), [FastAPI](https://fastapi.tiangolo.com/) and [Docker](https://docs.docker.com/) can facilite a couple aspects of such a task. Within this context, this notebook represents the development part of the model, where a data scientist would create a few models, evaluate it using some metrics and select the best one based in a metric. There are a lot of different machine learning tools that can be used in order to create models. It is important to note that the objective of this notebook is to give a broad overview of and end to end machine learning process, and therefore it is recommended to have the documentation of the frameworks used here as a companion. Also, the README file from the project explains how to reproduce the whole project.\n",
    "\n",
    "The rest of the notebook is organized as follows\n",
    "- 1) The Problem;\n",
    "- 2) Setting up an MLFlow Experiment;\n",
    "- 3) Training different Models;\n",
    "- 4) Setting the Best Model to Production.\n",
    "\n",
    "The code bellow imports everything that will be used throughout the notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/media/vinicius/Dados/poetry/virtualenvs/ml-pipes-VBbH4xSK-py3.8/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "from settings import EXPERIMENT_NAME, TRACKING_URI, FOLDS, CREDIT_CARD_MODEL_NAME,\\\n",
    "     CHAMPION_METRIC, THRESHOLD  # pylint: disable=import-error\n",
    "from dao.CreditCardDefault \\\n",
    "    import load_creditcard_dataset  # pylint: disable=import-error\n",
    "\n",
    "from trainers.h2o_automl import H2OClassifier  # pylint: disable=import-error\n",
    "from trainers.pycaret import PycaretClassifier  # pylint: disable=import-error\n",
    "from trainers.spark import SparkClassifier\n"
   ]
  },
  {
   "source": [
    "## 1) The problem\n",
    "\n",
    "The first thing we need to have to build a model is a problem to solve. Here it is used as example the [Credit Card Default from Kagle](https://www.kaggle.com/mlg-ulb/creditcardfraud), where basically the objective if to predict based on a few features whether or not a client will default on its credit card. The taret variable can assume the values 1, for default, and 0 for non default. Therefore it is a binary classification problem.\n",
    "\n",
    "Bellow the dataset is imported and the first rows of the dataset. Note that the Time column has been removed from the original dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "200189  1.033582 -2.621792 -3.251804 -0.500861 -0.395390 -1.163878  1.134247   \n",
       "155297  1.990823 -0.870545  0.214914 -1.157879 -1.475537 -0.763730 -1.220875   \n",
       "261753 -1.393086  0.402477 -1.621323 -2.322490  4.148880  2.561888  0.306946   \n",
       "54389  -1.704877  0.846411  1.458498  1.079633 -0.076459  2.276932 -0.592077   \n",
       "104641 -1.237854 -0.408139  0.536858  1.144366 -0.971648  0.278525  2.106226   \n",
       "\n",
       "              V8        V9       V10       V11       V12       V13       V14  \\\n",
       "200189 -0.616137 -1.153654  0.848405  0.508666 -0.804936 -1.452406  1.050677   \n",
       "155297 -0.074041  3.972540 -1.363667  0.221974 -1.758291  1.816691  1.063244   \n",
       "261753  0.641505  0.577496 -0.117790  0.102750 -0.160917 -0.555731 -1.158478   \n",
       "54389   1.172378  0.766775  0.031253 -1.134856  0.810819  0.003739 -0.651572   \n",
       "104641 -0.035919 -0.494001 -0.418671 -0.545098 -0.907083 -1.349666  0.679001   \n",
       "\n",
       "             V15       V16       V17       V18       V19       V20       V21  \\\n",
       "200189 -0.935653  0.439022  0.342379 -0.948848  0.895892  1.148596  0.884378   \n",
       "155297  0.868342 -0.019162  0.227641  0.875643  0.143164 -0.194225  0.101207   \n",
       "261753 -0.476826  0.495332 -0.227062 -0.587094 -1.504241 -0.146884 -0.485678   \n",
       "54389  -1.711017 -0.717726  0.390152  0.258140  2.081909  0.362971 -0.360434   \n",
       "104641  1.466117 -0.464970  0.135201  0.020574 -0.060248  1.067553  0.406148   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "200189  1.096179 -0.821193 -0.297833  0.480863  0.242767 -0.226397  0.001097   \n",
       "155297  0.810125  0.180105  0.031017 -0.366051 -0.221706  0.041138 -0.033284   \n",
       "261753 -0.815513 -0.224575  0.621516 -0.749052 -0.111526  0.514452  0.115925   \n",
       "54389  -0.446728 -0.400099 -1.680523  0.628227 -0.095864  0.504233  0.208201   \n",
       "104641  0.442708  1.003581 -0.012701 -0.117755 -0.297227  0.257509  0.256262   \n",
       "\n",
       "        Amount  Class  \n",
       "200189  650.46      0  \n",
       "155297   19.99      0  \n",
       "261753    8.93      0  \n",
       "54389    49.90      0  \n",
       "104641  468.00      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>200189</th>\n      <td>1.033582</td>\n      <td>-2.621792</td>\n      <td>-3.251804</td>\n      <td>-0.500861</td>\n      <td>-0.395390</td>\n      <td>-1.163878</td>\n      <td>1.134247</td>\n      <td>-0.616137</td>\n      <td>-1.153654</td>\n      <td>0.848405</td>\n      <td>0.508666</td>\n      <td>-0.804936</td>\n      <td>-1.452406</td>\n      <td>1.050677</td>\n      <td>-0.935653</td>\n      <td>0.439022</td>\n      <td>0.342379</td>\n      <td>-0.948848</td>\n      <td>0.895892</td>\n      <td>1.148596</td>\n      <td>0.884378</td>\n      <td>1.096179</td>\n      <td>-0.821193</td>\n      <td>-0.297833</td>\n      <td>0.480863</td>\n      <td>0.242767</td>\n      <td>-0.226397</td>\n      <td>0.001097</td>\n      <td>650.46</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155297</th>\n      <td>1.990823</td>\n      <td>-0.870545</td>\n      <td>0.214914</td>\n      <td>-1.157879</td>\n      <td>-1.475537</td>\n      <td>-0.763730</td>\n      <td>-1.220875</td>\n      <td>-0.074041</td>\n      <td>3.972540</td>\n      <td>-1.363667</td>\n      <td>0.221974</td>\n      <td>-1.758291</td>\n      <td>1.816691</td>\n      <td>1.063244</td>\n      <td>0.868342</td>\n      <td>-0.019162</td>\n      <td>0.227641</td>\n      <td>0.875643</td>\n      <td>0.143164</td>\n      <td>-0.194225</td>\n      <td>0.101207</td>\n      <td>0.810125</td>\n      <td>0.180105</td>\n      <td>0.031017</td>\n      <td>-0.366051</td>\n      <td>-0.221706</td>\n      <td>0.041138</td>\n      <td>-0.033284</td>\n      <td>19.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>261753</th>\n      <td>-1.393086</td>\n      <td>0.402477</td>\n      <td>-1.621323</td>\n      <td>-2.322490</td>\n      <td>4.148880</td>\n      <td>2.561888</td>\n      <td>0.306946</td>\n      <td>0.641505</td>\n      <td>0.577496</td>\n      <td>-0.117790</td>\n      <td>0.102750</td>\n      <td>-0.160917</td>\n      <td>-0.555731</td>\n      <td>-1.158478</td>\n      <td>-0.476826</td>\n      <td>0.495332</td>\n      <td>-0.227062</td>\n      <td>-0.587094</td>\n      <td>-1.504241</td>\n      <td>-0.146884</td>\n      <td>-0.485678</td>\n      <td>-0.815513</td>\n      <td>-0.224575</td>\n      <td>0.621516</td>\n      <td>-0.749052</td>\n      <td>-0.111526</td>\n      <td>0.514452</td>\n      <td>0.115925</td>\n      <td>8.93</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54389</th>\n      <td>-1.704877</td>\n      <td>0.846411</td>\n      <td>1.458498</td>\n      <td>1.079633</td>\n      <td>-0.076459</td>\n      <td>2.276932</td>\n      <td>-0.592077</td>\n      <td>1.172378</td>\n      <td>0.766775</td>\n      <td>0.031253</td>\n      <td>-1.134856</td>\n      <td>0.810819</td>\n      <td>0.003739</td>\n      <td>-0.651572</td>\n      <td>-1.711017</td>\n      <td>-0.717726</td>\n      <td>0.390152</td>\n      <td>0.258140</td>\n      <td>2.081909</td>\n      <td>0.362971</td>\n      <td>-0.360434</td>\n      <td>-0.446728</td>\n      <td>-0.400099</td>\n      <td>-1.680523</td>\n      <td>0.628227</td>\n      <td>-0.095864</td>\n      <td>0.504233</td>\n      <td>0.208201</td>\n      <td>49.90</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>104641</th>\n      <td>-1.237854</td>\n      <td>-0.408139</td>\n      <td>0.536858</td>\n      <td>1.144366</td>\n      <td>-0.971648</td>\n      <td>0.278525</td>\n      <td>2.106226</td>\n      <td>-0.035919</td>\n      <td>-0.494001</td>\n      <td>-0.418671</td>\n      <td>-0.545098</td>\n      <td>-0.907083</td>\n      <td>-1.349666</td>\n      <td>0.679001</td>\n      <td>1.466117</td>\n      <td>-0.464970</td>\n      <td>0.135201</td>\n      <td>0.020574</td>\n      <td>-0.060248</td>\n      <td>1.067553</td>\n      <td>0.406148</td>\n      <td>0.442708</td>\n      <td>1.003581</td>\n      <td>-0.012701</td>\n      <td>-0.117755</td>\n      <td>-0.297227</td>\n      <td>0.257509</td>\n      <td>0.256262</td>\n      <td>468.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset = load_creditcard_dataset()\n",
    "dataset.head()"
   ]
  },
  {
   "source": [
    "## 2) Setting up an MLFlow Experiment\n",
    "\n",
    "Now that a problem has been stated and some data to help solving the problem has been gathered, the next step is to setup a MLFlow experiment to log our models. **MLFlow is built upon the concept of experiments. A experiment is a series of fits, where parameters, metrics, models and artifacts can be associated with the respective fit (in an machine learning package agnostic way).**\n",
    "\n",
    "The code bellow tries to create an experiment, if that experiments already existis then it sets the experiment to the active one.\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5000'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "TRACKING_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME='teste'\n",
    "# TRACKING_URI='http://127.0.0.1:5000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "try:\n",
    "    experiment = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "except Exception:\n",
    "    client = MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "source": [
    "## 3) Training different Models\n",
    "\n",
    "The ext step if to train, evaluate and log a few different models. In order to demonstrate that MLFlow allows us to use different machine learning packages we will train an H2O autoML and SkLearn models (using pycaret). Now is the time where MLFlow is put into action: For each model that if fitted it will be logged a few parameters, metrics, artifacts and the models it self. To understand how this is done it checkout the classifiers definitions in `src/trainers/` folder and the [MLFlow Logging Documentaion](https://www.mlflow.org/docs/latest/tracking.html#logging-data-to-runs), ot all happens inside the `mlflow.start_run()` context manager. \n",
    "\n",
    "The next cells will train different classifiers. Once they finish running you can deploy the [MLFlow Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui) by executing `mlflow ui -p 5000 --backend-store-uri sqlite:///mlruns.db` in the terminal inside the `src/` folder. and see the results at [127.0.0.1:5000](127.0.0.1:5000)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://127.0.0.1:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minio_access_key'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'MINIO_SECRET_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.20.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.20.04, mixed mode, sharing)\n",
      "  Starting server from /media/vinicius/Dados/poetry/virtualenvs/ml-pipes-VBbH4xSK-py3.8/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp50onhnib\n",
      "  JVM stdout: /tmp/tmp50onhnib/h2o_vinicius_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp50onhnib/h2o_vinicius_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "--------------------------  ------------------------------------------------------------------\nH2O_cluster_uptime:         01 secs\nH2O_cluster_timezone:       America/Sao_Paulo\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.32.1.1\nH2O_cluster_version_age:    1 month and 24 days\nH2O_cluster_name:           H2O_from_python_vinicius_s1zztd\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    3 Gb\nH2O_cluster_total_cores:    8\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         accepting new members, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nH2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython_version:             3.8.5 final\n--------------------------  ------------------------------------------------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>01 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>America/Sao_Paulo</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.32.1.1</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 24 days </td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_vinicius_s1zztd</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>3 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>accepting new members, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>H2O_API_Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python_version:</td>\n<td>3.8.5 final</td></tr></table></div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |\n",
      "16:41:39.161: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.48985046706686136.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.48985046706686136.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.48985046706686136.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.48985046706686136.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.48985046706686136.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<trainers.h2o_automl.H2OClassifier at 0x7f6d15c26a60>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "H2OClassifier(\n",
    "    run_name='H2O',\n",
    "    max_mem_size='3G',\n",
    "    threshold=THRESHOLD,\n",
    "    df=dataset,\n",
    "    target_col='Class',\n",
    "    sort_metric='aucpr',\n",
    "    max_models=8,\n",
    "    max_runtime_secs=10,\n",
    "    nfolds=FOLDS,\n",
    "    seed=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "              Parameters\nalpha                1.0\nclass_weight        None\ncopy_X              True\nfit_intercept       True\nmax_iter            None\nnormalize          False\nrandom_state       54321\nsolver              auto\ntol                0.001",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alpha</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>class_weight</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>copy_X</th>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>fit_intercept</th>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>max_iter</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>normalize</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>random_state</th>\n      <td>54321</td>\n    </tr>\n    <tr>\n      <th>solver</th>\n      <td>auto</td>\n    </tr>\n    <tr>\n      <th>tol</th>\n      <td>0.001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error in logging parameter for                                 pycaret_precision_2\n",
      "[Errno 2] No such file or directory: 'Hyperparameters.png'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<trainers.pycaret.PycaretClassifier at 0x7fe3a9e986d0>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "PycaretClassifier(\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        run_name='Pycaret2',\n",
    "        sort_metric='precision',\n",
    "        df=dataset,\n",
    "        target='Class',\n",
    "        threshold=THRESHOLD,\n",
    "        n_best_models=3,\n",
    "        data_split_stratify=True,\n",
    "        nfolds=FOLDS,\n",
    "        normalize=True,\n",
    "        transformation=True,\n",
    "        ignore_low_variance=True,\n",
    "        remove_multicollinearity=True,\n",
    "        multicollinearity_threshold=0.95,\n",
    "        session_id=54321\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<trainers.spark.SparkClassifier at 0x7fe32bb66310>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "SparkClassifier(\n",
    "    df = dataset,\n",
    "    target_col = 'Class',\n",
    "    run_name = 'spark_classifier',\n",
    "    max_mem_size = 4,\n",
    "    n_cores = 4,\n",
    "    seed = 90\n",
    ")"
   ]
  },
  {
   "source": [
    "## 4) Setting the Best Model to Production\n",
    "\n",
    "The final step in this notebook if to set to production the model with the best selected metric, imported as `CHAMPION_METRIC`. This is done to show is is possible to create an automated workflow using MLFlow to deplot a model. However it is also possible to deplot the model using the [UI server](https://www.mlflow.org/docs/latest/model-registry.html#ui-workflow).\n",
    "\n",
    "Once this is done you can return to the README file to check how the model is now deployed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'CreditCardDefault' already exists. Creating a new version of this model...\n",
      "2021/05/19 09:02:38 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: CreditCardDefault, version 3\n",
      "Created version '3' of model 'CreditCardDefault'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1621425758707, current_stage='Staging', description='Deploying model with model registery', last_updated_timestamp=1621425758825, name='CreditCardDefault', run_id='c325b227a2d24a3994ca8e75b0201117', run_link='', source='/media/vinicius/Dados/projects/ml-pipes/mlflow_artifact_store/1/c325b227a2d24a3994ca8e75b0201117/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='3'>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Getting The best Model according to CHAMPION_METRIC\n",
    "champion = MlflowClient().search_runs(\n",
    "    experiment_ids=[\n",
    "        str(\n",
    "            mlflow.get_experiment_by_name(name=EXPERIMENT_NAME).experiment_id\n",
    "        )\n",
    "    ],\n",
    "    run_view_type=ViewType.ALL,\n",
    "    order_by=[f\"metrics.{CHAMPION_METRIC} DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = champion[0].info.run_id\n",
    "\n",
    "# Registering Model in model registery\n",
    "model = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/model\",\n",
    "    name=CREDIT_CARD_MODEL_NAME\n",
    ")\n",
    "\n",
    "# Setting version 1\n",
    "MlflowClient().update_model_version(\n",
    "    name=CREDIT_CARD_MODEL_NAME,\n",
    "    version=model.version,\n",
    "    description='Deploying model with model registery'\n",
    ")\n",
    "\n",
    "# Setting it to production\n",
    "MlflowClient().transition_model_version_stage(\n",
    "    name=CREDIT_CARD_MODEL_NAME,\n",
    "    version=model.version,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}